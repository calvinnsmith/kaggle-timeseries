{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files below have to be downloaded from kaggle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv',index_col = False)\n",
    "test = pd.read_csv('test.csv')\n",
    "holidays = pd.read_csv('holidays_events.csv')\n",
    "oil = pd.read_csv('oil.csv')\n",
    "sample_sub = pd.read_csv('sample_submission.csv')\n",
    "stores = pd.read_csv('stores.csv')\n",
    "transactions = pd.read_csv('transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_stores(df,stores):\n",
    "    df = pd.merge(df,stores,how = 'left',on = 'store_nbr')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_oil(df,oil):\n",
    "\n",
    "\n",
    "    dates = pd.DataFrame({'date':df['date'].unique()})\n",
    "\n",
    "    oil_df = pd.merge(dates,oil,how = 'left',on = 'date')\n",
    "    oil_df['dcoilwtico'][0] = oil_df['dcoilwtico'][1].copy()\n",
    "    oil_df['dcoilwtico'] = oil_df['dcoilwtico'].interpolate(method = 'linear')\n",
    "    df = pd.merge(df,oil,how = 'left',on = 'date')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_holidays(df,holidays):\n",
    "\n",
    "    dates = pd.DataFrame({'date':df['date'].unique()})\n",
    "\n",
    "    holidays = holidays[holidays['transferred'] == False]\n",
    "\n",
    "    #national\n",
    "    national_holidays = holidays[holidays['locale'] == 'National'][['date','locale']]\n",
    "    national_holidays['is_national'] = 1\n",
    "    national_holidays.drop_duplicates(subset='date', keep=\"first\", inplace=True)\n",
    "    \n",
    "\n",
    "    national = pd.merge(dates,national_holidays,how = 'left',on = 'date')\n",
    "    national['is_national'] = national['is_national'].fillna(0)\n",
    "\n",
    "    df = pd.merge(df,national,how = 'left',on = 'date')\n",
    "    df.drop(columns = 'locale',inplace = True)\n",
    "\n",
    "    #regional\n",
    "    regional_holidays = holidays[holidays['locale'] == 'Regional'][['date','locale_name']]\n",
    "    regional_holidays['is_regional'] = 1\n",
    "\n",
    "    df = pd.merge(df,regional_holidays,how = 'left',left_on = ['date','state'],right_on = ['date','locale_name'])\n",
    "    df.drop(columns = 'locale_name',inplace = True)\n",
    "    df['is_regional'] = df['is_regional'].fillna(0)\n",
    "\n",
    "    #local\n",
    "    local_holidays = holidays[holidays['locale'] == 'Local'][['date','locale_name']]\n",
    "    local_holidays['is_local'] = 1\n",
    "    local_holidays.drop([265],inplace = True)\n",
    "\n",
    "    df = pd.merge(df,local_holidays,how = 'left',left_on = ['date','city'],right_on = ['date','locale_name'])\n",
    "    df.drop(columns = 'locale_name',inplace = True)\n",
    "    df['is_local'] = df['is_local'].fillna(0)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_transactions(df,transactions,is_test = False):\n",
    "\n",
    "    dates = pd.DataFrame({'date':df['date'].unique()})\n",
    "\n",
    "    if is_test == True:\n",
    "        df = pd.merge(df,transactions,how = 'left',on = ['date','store_nbr'])\n",
    "        df['is_closed'] = 0\n",
    "    else:\n",
    "        df = pd.merge(df,transactions,how = 'left',on = ['date','store_nbr'])\n",
    "        df['is_closed'] = df['transactions'].isna()*1\n",
    "        df['transactions'].fillna(0,inplace= True)\n",
    "  \n",
    "    return df    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_previous_month(df):\n",
    "    df_grouped =  df.groupby(['year','month','family'])['sales'].sum().reset_index()\n",
    "\n",
    "    items_list = df['family'].unique()\n",
    "\n",
    "    new_df = pd.DataFrame(columns = ['year','month','family','sales','previous_month_sales'])\n",
    "\n",
    "    for item in items_list:\n",
    "        df_item = df_grouped[df_grouped['family'] == item]\n",
    "        df_item['previous_month_sales'] = df_item['sales'].shift(1)\n",
    "\n",
    "        new_df = new_df.append(df_item)\n",
    "\n",
    "    new_df.drop(columns = 'sales',inplace= True)\n",
    "\n",
    "    df = pd.merge(df,new_df,how = 'left',on = ['year','month','family'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline():\n",
    "    train = pd.read_csv('train.csv')\n",
    "    test = pd.read_csv('test.csv')\n",
    "    holidays = pd.read_csv('holidays_events.csv')\n",
    "    oil = pd.read_csv('oil.csv')\n",
    "    stores = pd.read_csv('stores.csv')\n",
    "    transactions = pd.read_csv('transactions.csv')\n",
    "\n",
    "    train_temp = add_transactions(create_holidays(merge_oil(merge_stores(train,stores),oil),holidays),transactions)\n",
    "    test_temp = add_transactions(create_holidays(merge_oil(merge_stores(test,stores),oil),holidays),transactions)\n",
    "    test_temp['sales'] = np.nan\n",
    "\n",
    "    full_data = pd.concat([train_temp,test_temp])\n",
    "\n",
    "    full_data['family'] = full_data['family'].str.replace(' ','')\n",
    "    full_data['family'] = full_data['family'].str.replace('/','')\n",
    "\n",
    "\n",
    "\n",
    "    list_of_items = full_data['family'].unique()\n",
    "\n",
    "\n",
    "    full_data['date'] = pd.to_datetime(full_data['date'])\n",
    "    full_data['dayofweek'] = pd.to_datetime(full_data['date']).dt.day_of_week\n",
    "    full_data['dayofyear'] = pd.to_datetime(full_data['date']).dt.day_of_year\n",
    "    full_data['dayofmonth'] = pd.to_datetime(full_data['date']).dt.day\n",
    "    full_data['store_nbr'] = full_data['store_nbr'].astype('str')\n",
    "    full_data['cluster'] = full_data['cluster'].astype('str')\n",
    "    full_data['year'] = pd.to_datetime(full_data['date']).dt.year\n",
    "    full_data['month'] = pd.to_datetime(full_data['date']).dt.month\n",
    "\n",
    "    full_data = get_previous_month(full_data)\n",
    "    \n",
    "    full_data.drop(columns = ['year','month'],inplace = True)\n",
    "    \n",
    "    \n",
    "    full_data['sales'] = np.log1p(full_data['sales']+1)\n",
    "    full_data['previous_month_sales'] = np.log1p(full_data['previous_month_sales'] + 1)\n",
    "\n",
    "    \n",
    "    os.chdir('data')\n",
    "    \n",
    "    for item in list_of_items:\n",
    "\n",
    "        item_df = full_data[full_data['family'] == item]\n",
    "        item_df.drop(columns = ['family'],inplace= True)\n",
    "        item_df = pd.get_dummies(item_df)\n",
    "        item_df.columns = item_df.columns.str.replace('_','')\n",
    "        item_df.columns = item_df.columns.str.replace('/','')\n",
    "        item_df.columns = item_df.columns.str.replace(' ','')\n",
    "        item_df.columns = item_df.columns.str.replace(',','')\n",
    "\n",
    "        item_df.to_csv(str(item)+'.csv',index = False)\n",
    "\n",
    "    os.chdir('../')      \n",
    "    \n",
    "    del train\n",
    "    del test\n",
    "    del holidays\n",
    "    del oil\n",
    "    del stores\n",
    "    del transactions\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pipeline()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running GBM over all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "#train[train.columns] = scaler.fit_transform(train[train.columns])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating one model for each Item"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the LGB model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbmr_model = LGBMRegressor(\n",
    "        colsample_bytree=0.7,\n",
    "        learning_rate=0.055,\n",
    "        min_child_samples=10,\n",
    "        num_leaves=19,\n",
    "        objective='regression',\n",
    "        n_estimators=1000,\n",
    "        n_jobs=4,\n",
    "        random_state=337)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_lgbrm(df):\n",
    "    df = df.set_index('id',drop = True)\n",
    "    df = df[:-864]\n",
    "\n",
    "    #df.drop(columns = 'previousmonthsales',inplace = True)\n",
    "\n",
    "    # training \n",
    "    x_train = df[:-864]\n",
    "    y_train = x_train['sales']\n",
    "    x_train.drop(columns=['sales','date' ],inplace=True)\n",
    "    x_train[x_train.columns] = scaler.fit_transform(x_train[x_train.columns])\n",
    "\n",
    "    # validation\n",
    "    x_val = df[-864:]\n",
    "    y_val = x_val['sales']\n",
    "    x_val.drop(columns=['sales','date' ],inplace=True)\n",
    "    x_val[x_val.columns] = scaler.transform(x_val[x_val.columns])\n",
    "\n",
    "    lgbmr_model.fit(x_train,y_train)\n",
    "\n",
    "    predictions = lgbmr_model.predict(x_val)\n",
    "\n",
    "    predictions = [0 if x < 0 else x for x in predictions]\n",
    "\n",
    "    rmsle = mean_squared_log_error(y_val,predictions)\n",
    "\n",
    "    \n",
    "\n",
    "    return rmsle \n",
    "\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code runs the training + testing with the validation function and prints the RMSLE score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('data')\n",
    "rmsle = 0\n",
    "for file in os.listdir():\n",
    "    df = pd.read_csv(file)\n",
    "    rmsle = rmsle + validate_lgbrm(df)\n",
    "    \n",
    "\n",
    "print(rmsle)\n",
    "\n",
    "os.chdir('../')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for training and testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lgbrm(df):\n",
    "    \n",
    "\n",
    "    df = df.set_index('id',drop = True)\n",
    "\n",
    "    df.drop(columns = 'previousmonthsales',inplace = True)\n",
    "    \n",
    "    # training\n",
    "    x_train = df[df['date'] < '2017-08-16']\n",
    "    y_train = x_train['sales']\n",
    "    x_train.drop(columns=['sales','date' ],inplace=True)\n",
    "    x_train[x_train.columns] = scaler.fit_transform(x_train[x_train.columns])\n",
    "\n",
    "    # testing    \n",
    "    x_test = df[df['date'] >= '2017-08-16']\n",
    "    x_test.drop(columns=['sales','date' ],inplace=True)\n",
    "    x_test[x_test.columns] = scaler.transform(x_test[x_test.columns])\n",
    "\n",
    "\n",
    "    # Fitting model to training data and predicting on the testing set\n",
    "    lgbmr_model.fit(x_train,y_train)\n",
    "    x_test['sales'] = lgbmr_model.predict(x_test)\n",
    "\n",
    "    \n",
    "\n",
    "    return x_test.reset_index()[['id','sales']]\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code runs training and testing on all datasets and creates a list of predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('data')\n",
    "predicted = pd.DataFrame(columns = ['id','sales'])\n",
    "for file in os.listdir():\n",
    "    df = pd.read_csv(file)\n",
    "    predicted = predicted.append(run_lgbrm(df),ignore_index = True)\n",
    "    \n",
    "\n",
    "\n",
    "os.chdir('../')\n",
    "\n",
    "predicted['sales'] = np.expm1(predicted['sales']) - 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we set negative predictions to zero and sort the list before saving:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted['sales'] = [0 if x < 0 else x for x in predicted['sales']]\n",
    "\n",
    "predicted.sort_values(by = 'id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted.sort_values(by = 'id').to_csv('predictions.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
